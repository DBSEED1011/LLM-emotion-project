{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f58986",
   "metadata": {},
   "source": [
    "# Check whether the experimental settings match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e78b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check completed\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import ipynbname\n",
    "\n",
    "path = os.path.dirname(ipynbname.path())\n",
    "folder_path =  os.path.join(path,\"prompt\")\n",
    "pattern = re.compile(r\"(\\d+)_character\\.json$\")\n",
    "\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "file_pairs = {}\n",
    "\n",
    "# Find matching pairs of \"character.json\" and \"game_setting_prompt.json\"\n",
    "for file_name in files:\n",
    "    match = pattern.match(file_name)\n",
    "    if match:\n",
    "        prefix = match.group(1)\n",
    "        character_file = file_name\n",
    "        setting_file = f\"{prefix}_game_setting_prompt.json\"\n",
    "        if setting_file in files:\n",
    "            file_pairs[prefix] = (character_file, setting_file)\n",
    "\n",
    "# Compare IDs between each pair of files\n",
    "for prefix, (file1_name, file2_name) in file_pairs.items():\n",
    "    file1_path = os.path.join(folder_path, file1_name)\n",
    "    file2_path = os.path.join(folder_path, file2_name)\n",
    "\n",
    "    with open(file1_path, \"r\", encoding=\"utf-8\") as file1:\n",
    "        data1 = json.load(file1)\n",
    "\n",
    "    with open(file2_path, \"r\", encoding=\"utf-8\") as file2:\n",
    "        data2 = json.load(file2)\n",
    "\n",
    "    ids1 = {item[\"id\"] for item in data1}\n",
    "    ids2 = {item[\"id\"] for item in data2}\n",
    "\n",
    "    # Check if the ID sets are different\n",
    "    if ids1 != ids2:\n",
    "        print(f\"ID values are inconsistent between {prefix}_character.json and {prefix}_game_setting_prompt.json (prefix: {prefix})\")\n",
    "\n",
    "print(\"Check completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb87a84",
   "metadata": {},
   "source": [
    "# Check whether the prompt is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564d08c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check completed\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "path = os.path.dirname(ipynbname.path())\n",
    "folder_path =  os.path.join(path,\"prompt\")\n",
    "pattern = re.compile(r\"(\\d+)_game_setting_prompt.json$\")\n",
    "\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Check whether the maximum value equals 60\n",
    "for file_name in files:\n",
    "    match = pattern.match(file_name)\n",
    "    if match:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        max_trial = max(item[\"trial\"] for item in data)\n",
    "        if max_trial != 60:\n",
    "            print(f\"In {file_name}, the maximum item['trial'] value is {max_trial}, which does not meet the requirement.\")\n",
    "\n",
    "print(\"Check completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724abcf",
   "metadata": {},
   "source": [
    "# Check whether the output file format is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff8f13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files for all models have been checked\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List of models to check\n",
    "models = [\"gpt-3.5-turbo-0125\", \"o3-mini-2025-01-31\", \"deepseek-r1\", \"deepseek-v3\"]\n",
    "persona = \"persona\"\n",
    "emotion = \"emotion\"\n",
    "temperature = \"1.0\"\n",
    "\n",
    "# Columns to check\n",
    "required_cols = [\"AA_valence\", \"AA_arousal\", \"choice\", \"AC_valence\", \"AC_arousal\"]\n",
    "\n",
    "def check_file(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=\"\\t\", header=0)\n",
    "    except Exception as e:\n",
    "        return f\"Failed to read: {e}\"\n",
    "\n",
    "    if len(df) != 60:\n",
    "        return f\"Incorrect number of rows: actual {len(df)}, expected 60\"\n",
    "\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            return f\"Missing column {col}\"\n",
    "\n",
    "    if df[required_cols].isnull().any().any():\n",
    "        return \"Missing values found in required columns\"\n",
    "\n",
    "    if not df[\"choice\"].dropna().isin([0, 1]).all():\n",
    "        return \"'choice' column contains invalid values\"\n",
    "\n",
    "    for col in required_cols:\n",
    "        if col != \"choice\":\n",
    "            if not df[col].dropna().between(-100, 100).all():\n",
    "                return f\"Column {col} is out of range (-100, 100)\"\n",
    "\n",
    "    return \"Format correct\"\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    path = os.path.dirname(ipynbname.path())\n",
    "    folder_path =  os.path.join(path,f\"result_{persona}_{emotion}_{temperature}_{model}\")\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder does not exist: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            result = check_file(file_path)\n",
    "            if result != \"Format correct\":\n",
    "            #    os.remove(file_path)\n",
    "                print(f\"{file_name} in {model}: Format error -> {result}\")\n",
    "\n",
    "print(\"All files for all models have been checked\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98591f09",
   "metadata": {},
   "source": [
    "# Check for missing agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2127eb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All samples present in gpt-3.5-turbo-0125\n",
      "All samples present in o3-mini-2025-01-31\n",
      "All samples present in deepseek-r1\n",
      "All samples present in deepseek-v3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List of models to check\n",
    "models = [\"gpt-3.5-turbo-0125\", \"o3-mini-2025-01-31\", \"deepseek-r1\", \"deepseek-v3\"]\n",
    "persona = \"persona\"\n",
    "emotion = \"emotion\"\n",
    "temperature = \"1.0\"\n",
    "\n",
    "# Expected sample numbers\n",
    "# Please note that this is only an example, which includes results from only two agents.\n",
    "expected_numbers = range(0, 2)\n",
    "\n",
    "for model in models:\n",
    "    path = os.path.dirname(ipynbname.path())\n",
    "    folder_path =  os.path.join(path,f\"result_{persona}_{emotion}_{temperature}_{model}\")\n",
    "\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Folder does not exist: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    missing_numbers = [\n",
    "        n for n in expected_numbers\n",
    "        if not os.path.isfile(os.path.join(folder_path, f\"output_{n}.txt\"))\n",
    "    ]\n",
    "\n",
    "    if missing_numbers:\n",
    "        print(f\"Missing samples in {model}: {missing_numbers}\")\n",
    "    else:\n",
    "        print(f\"All samples present in {model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97ca264",
   "metadata": {},
   "source": [
    "# Merged the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2d448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: gpt-3.5-turbo-0125\n",
      "Processing model: o3-mini-2025-01-31\n",
      "Processing model: deepseek-r1\n",
      "Processing model: deepseek-v3\n",
      "Results saved: merged_all_models_persona_emotion_1.0.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "models = [\n",
    "    \"gpt-3.5-turbo-0125\",\n",
    "    \"o3-mini-2025-01-31\",\n",
    "    \"deepseek-r1\",\n",
    "    \"deepseek-v3\"\n",
    "]\n",
    "\n",
    "# Parameter definition\n",
    "persona = \"persona\"\n",
    "emotion = \"emotion\"\n",
    "temperature = \"1.0\"\n",
    "\n",
    "output_file = f\"merged_all_models_{persona}_{emotion}_{temperature}.txt\"\n",
    "all_dfs = []\n",
    "\n",
    "path = os.path.dirname(ipynbname.path())\n",
    "\n",
    "for model in models:\n",
    "    print(f\"Processing model: {model}\")\n",
    "    \n",
    "    prompt_folder = os.path.join(path,\"prompt\")\n",
    "    result_folder = os.path.join(path,f\"result_{persona}_{emotion}_{temperature}_{model}\")\n",
    "\n",
    "    prompt_files = glob(os.path.join(prompt_folder, \"*_game_setting_prompt.json\"))\n",
    "\n",
    "    for prompt_file in prompt_files:\n",
    "        prefix = os.path.basename(prompt_file).split('_')[0]\n",
    "        result_file = os.path.join(result_folder, f\"output_{prefix}.txt\")\n",
    "        if not os.path.exists(result_file):\n",
    "            print(f\"Result file for prefix {prefix} and model {model} does not exist. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        with open(prompt_file, 'r', encoding='utf-8') as f:\n",
    "            prompt_data = json.load(f)\n",
    "        prompt_df = pd.DataFrame(prompt_data)\n",
    "        prompt_df['group'] = model    \n",
    "\n",
    "        result_df = pd.read_csv(result_file, sep='\\t', header=0)\n",
    "\n",
    "        extra_cols = [c for c in prompt_df.columns if 'index' in c or c == 'Unnamed']\n",
    "        if extra_cols:\n",
    "            prompt_df = prompt_df.drop(columns=extra_cols)\n",
    "\n",
    "        merged_df = pd.concat([prompt_df, result_df], axis=1)\n",
    "        all_dfs.append(merged_df)\n",
    "\n",
    "if all_dfs:\n",
    "    final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    final_df.to_csv(output_file, sep='\\t', index=False, encoding='utf-8')\n",
    "    print(f\"Results saved: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
